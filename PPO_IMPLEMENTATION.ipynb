{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kalhapure100/PPO-IMPLEMENTATION/blob/main/PPO_IMPLEMENTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l18wZLz2cuRo"
      },
      "source": [
        "Part I\n",
        "\n",
        "* Import libraries\n",
        "* Define PPO algoroithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hiwZRTLcE-Ch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p5WuwlBzel4_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "exiLfJZoiB8K"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import MultivariateNormal\n",
        "from torch.distributions import Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YBMFnLv5iNaG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZcutuzpkKVD",
        "outputId": "500bdb5a-048e-482a-c9c2-c35665041106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pybullet in /usr/local/lib/python3.10/dist-packages (3.2.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pybullet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q71ApEGfkazR",
        "outputId": "dab1f599-e482-4bfe-9439-98aeaea120f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device set to : cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu')\n",
        "\n",
        "if(torch.cuda.is_available()):\n",
        "    device = torch.device('cuda:0')\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
        "else:\n",
        "    print(\"Device set to : cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dzUInpgVko9W"
      },
      "outputs": [],
      "source": [
        "class RolloutBuffer:\n",
        "    def __init__(self):\n",
        "        self.actions = []\n",
        "        self.states = []\n",
        "        self.logprobs = []\n",
        "        self.rewards = []\n",
        "        self.state_values = []\n",
        "        self.is_terminals = []\n",
        "    def clear(self):\n",
        "        del self.actions[:]\n",
        "        del self.states[:]\n",
        "        del self.logprobs[:]\n",
        "        del self.rewards[:]\n",
        "        del self.state_values[:]\n",
        "        del self.is_terminals[:]\n",
        "class ActorCritic(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_dim = action_dim\n",
        "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
        "\n",
        "        # actor\n",
        "        if has_continuous_action_space :\n",
        "            self.actor = nn.Sequential(\n",
        "                            nn.Linear(state_dim, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, action_dim),\n",
        "                            nn.Tanh()\n",
        "                        )\n",
        "        else:\n",
        "            self.actor = nn.Sequential(\n",
        "                            nn.Linear(state_dim, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, 64),\n",
        "                            nn.Tanh(),\n",
        "                            nn.Linear(64, action_dim),\n",
        "                            nn.Softmax(dim=-1)\n",
        "                        )\n",
        "\n",
        "\n",
        "        # critic\n",
        "        self.critic = nn.Sequential(\n",
        "                        nn.Linear(state_dim, 64),\n",
        "                        nn.Tanh(),\n",
        "                        nn.Linear(64, 64),\n",
        "                        nn.Tanh(),\n",
        "                        nn.Linear(64, 1)\n",
        "                    )\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def forward(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "    def act(self, state):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action = dist.sample()\n",
        "        action_logprob = dist.log_prob(action)\n",
        "        state_val = self.critic(state)\n",
        "\n",
        "        return action.detach(), action_logprob.detach(), state_val.detach()\n",
        "\n",
        "\n",
        "    def evaluate(self, state, action):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            action_mean = self.actor(state)\n",
        "            action_var = self.action_var.expand_as(action_mean)\n",
        "            cov_mat = torch.diag_embed(action_var).to(device)\n",
        "            dist = MultivariateNormal(action_mean, cov_mat)\n",
        "\n",
        "            # for single action continuous environments\n",
        "            if self.action_dim == 1:\n",
        "                action = action.reshape(-1, self.action_dim)\n",
        "\n",
        "        else:\n",
        "            action_probs = self.actor(state)\n",
        "            dist = Categorical(action_probs)\n",
        "\n",
        "        action_logprobs = dist.log_prob(action)\n",
        "        dist_entropy = dist.entropy()\n",
        "        state_values = self.critic(state)\n",
        "\n",
        "        return action_logprobs, state_values, dist_entropy\n",
        "class PPO:\n",
        "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
        "\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "\n",
        "        if has_continuous_action_space:\n",
        "            self.action_std = action_std_init\n",
        "\n",
        "        self.gamma = gamma\n",
        "        self.eps_clip = eps_clip\n",
        "        self.K_epochs = K_epochs\n",
        "\n",
        "        self.buffer = RolloutBuffer()\n",
        "\n",
        "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
        "        self.optimizer = torch.optim.Adam([\n",
        "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
        "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
        "                    ])\n",
        "\n",
        "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "        self.MseLoss = nn.MSELoss()\n",
        "\n",
        "\n",
        "    def set_action_std(self, new_action_std):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = new_action_std\n",
        "            self.policy.set_action_std(new_action_std)\n",
        "            self.policy_old.set_action_std(new_action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            self.action_std = self.action_std - action_std_decay_rate\n",
        "            self.action_std = round(self.action_std, 4)\n",
        "            if (self.action_std <= min_action_std):\n",
        "                self.action_std = min_action_std\n",
        "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
        "            else:\n",
        "                print(\"setting actor output action_std to : \", self.action_std)\n",
        "            self.set_action_std(self.action_std)\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
        "\n",
        "        print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "    def select_action(self, state):\n",
        "\n",
        "        if self.has_continuous_action_space:\n",
        "            with torch.no_grad():\n",
        "                state = torch.FloatTensor(state).to(device)\n",
        "                action, action_logprob, state_val = self.policy_old.act(state)\n",
        "\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "            self.buffer.state_values.append(state_val)\n",
        "\n",
        "            return action.detach().cpu().numpy().flatten()\n",
        "\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                state = torch.FloatTensor(state).to(device)\n",
        "                action, action_logprob, state_val = self.policy_old.act(state)\n",
        "\n",
        "            self.buffer.states.append(state)\n",
        "            self.buffer.actions.append(action)\n",
        "            self.buffer.logprobs.append(action_logprob)\n",
        "            self.buffer.state_values.append(state_val)\n",
        "\n",
        "            return action.item()\n",
        "\n",
        "\n",
        "    def update(self):\n",
        "\n",
        "        # Monte Carlo estimate of returns\n",
        "        rewards = []\n",
        "        discounted_reward = 0\n",
        "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
        "            if is_terminal:\n",
        "                discounted_reward = 0\n",
        "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
        "            rewards.insert(0, discounted_reward)\n",
        "\n",
        "        # Normalizing the rewards\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
        "\n",
        "        # convert list to tensor\n",
        "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
        "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
        "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
        "        old_state_values = torch.squeeze(torch.stack(self.buffer.state_values, dim=0)).detach().to(device)\n",
        "\n",
        "        # calculate advantages\n",
        "        advantages = rewards.detach() - old_state_values.detach()\n",
        "\n",
        "\n",
        "        # Optimize policy for K epochs\n",
        "        for _ in range(self.K_epochs):\n",
        "\n",
        "            # Evaluating old actions and values\n",
        "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
        "\n",
        "            # match state_values tensor dimensions with rewards tensor\n",
        "            state_values = torch.squeeze(state_values)\n",
        "\n",
        "            # Finding the ratio (pi_theta / pi_theta__old)\n",
        "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
        "\n",
        "            # Finding Surrogate Loss\n",
        "            surr1 = ratios * advantages\n",
        "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
        "\n",
        "            # final loss of clipped objective PPO\n",
        "            loss = -torch.min(surr1, surr2) + 0.5 * self.MseLoss(state_values, rewards) - 0.01 * dist_entropy\n",
        "\n",
        "            # take gradient step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.mean().backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        # Copy new weights into old policy\n",
        "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
        "\n",
        "        # clear buffer\n",
        "        self.buffer.clear()\n",
        "\n",
        "\n",
        "    def save(self, checkpoint_path):\n",
        "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
        "\n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
        "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "przRzRajaILy"
      },
      "source": [
        "Part II\n",
        "\n",
        "*  Train PPO algo\n",
        "*  Save preTrained networks weights and log files.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD9r0fBrlcQc",
        "outputId": "4e1ddbfc-073f-4595-996f-4d8be5e9b06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training environment name : CartPole-v1\n",
            "current logging run number for CartPole-v1 :  1\n",
            "logging at : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_1.csv\n",
            "save checkpoint path : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "--------------------------------------------------------------------------------------------\n",
            "max training timesteps :  100000\n",
            "max timesteps per episode :  400\n",
            "model saving frequency : 20000 timesteps\n",
            "log frequency : 800 timesteps\n",
            "printing average reward over episodes in last : 1600 timesteps\n",
            "--------------------------------------------------------------------------------------------\n",
            "state space dimension :  4\n",
            "action space dimension :  2\n",
            "--------------------------------------------------------------------------------------------\n",
            "Initializing a discrete action space policy\n",
            "--------------------------------------------------------------------------------------------\n",
            "PPO update frequency : 1600 timesteps\n",
            "PPO K epochs :  40\n",
            "PPO epsilon clip :  0.2\n",
            "discount factor (gamma) :  0.99\n",
            "--------------------------------------------------------------------------------------------\n",
            "optimizer learning rate actor :  0.0003\n",
            "optimizer learning rate critic :  0.001\n",
            "Started training at (GMT) :  2024-08-21 14:37:08\n",
            "============================================================================================\n",
            "Episode : 75 \t\t Timestep : 1600 \t\t Average Reward : 21.28\n",
            "Episode : 138 \t\t Timestep : 3200 \t\t Average Reward : 25.32\n",
            "Episode : 190 \t\t Timestep : 4800 \t\t Average Reward : 30.37\n",
            "Episode : 220 \t\t Timestep : 6400 \t\t Average Reward : 53.67\n",
            "Episode : 244 \t\t Timestep : 8000 \t\t Average Reward : 63.67\n",
            "Episode : 254 \t\t Timestep : 9600 \t\t Average Reward : 161.2\n",
            "Episode : 264 \t\t Timestep : 11200 \t\t Average Reward : 165.4\n",
            "Episode : 273 \t\t Timestep : 12800 \t\t Average Reward : 166.33\n",
            "Episode : 284 \t\t Timestep : 14400 \t\t Average Reward : 155.45\n",
            "Episode : 291 \t\t Timestep : 16000 \t\t Average Reward : 212.57\n",
            "Episode : 298 \t\t Timestep : 17600 \t\t Average Reward : 229.86\n",
            "Episode : 304 \t\t Timestep : 19200 \t\t Average Reward : 276.67\n",
            "--------------------------------------------------------------------------------------------\n",
            "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "model saved\n",
            "Elapsed Time  :  0:00:37\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode : 312 \t\t Timestep : 20800 \t\t Average Reward : 201.12\n",
            "Episode : 317 \t\t Timestep : 22400 \t\t Average Reward : 264.4\n",
            "Episode : 323 \t\t Timestep : 24000 \t\t Average Reward : 303.83\n",
            "Episode : 328 \t\t Timestep : 25600 \t\t Average Reward : 302.2\n",
            "Episode : 334 \t\t Timestep : 27200 \t\t Average Reward : 266.33\n",
            "Episode : 341 \t\t Timestep : 28800 \t\t Average Reward : 254.86\n",
            "Episode : 346 \t\t Timestep : 30400 \t\t Average Reward : 318.8\n",
            "Episode : 352 \t\t Timestep : 32000 \t\t Average Reward : 264.33\n",
            "Episode : 358 \t\t Timestep : 33600 \t\t Average Reward : 267.17\n",
            "Episode : 362 \t\t Timestep : 35200 \t\t Average Reward : 357.5\n",
            "Episode : 366 \t\t Timestep : 36800 \t\t Average Reward : 389.75\n",
            "Episode : 374 \t\t Timestep : 38400 \t\t Average Reward : 227.0\n",
            "Episode : 379 \t\t Timestep : 40000 \t\t Average Reward : 298.6\n",
            "--------------------------------------------------------------------------------------------\n",
            "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "model saved\n",
            "Elapsed Time  :  0:00:58\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode : 384 \t\t Timestep : 41600 \t\t Average Reward : 334.0\n",
            "Episode : 388 \t\t Timestep : 43200 \t\t Average Reward : 372.75\n",
            "Episode : 392 \t\t Timestep : 44800 \t\t Average Reward : 386.25\n",
            "Episode : 396 \t\t Timestep : 46400 \t\t Average Reward : 400.0\n",
            "Episode : 401 \t\t Timestep : 48000 \t\t Average Reward : 340.4\n",
            "Episode : 405 \t\t Timestep : 49600 \t\t Average Reward : 400.0\n",
            "Episode : 409 \t\t Timestep : 51200 \t\t Average Reward : 400.0\n",
            "Episode : 413 \t\t Timestep : 52800 \t\t Average Reward : 400.0\n",
            "Episode : 418 \t\t Timestep : 54400 \t\t Average Reward : 328.4\n",
            "Episode : 422 \t\t Timestep : 56000 \t\t Average Reward : 400.0\n",
            "Episode : 426 \t\t Timestep : 57600 \t\t Average Reward : 400.0\n",
            "Episode : 430 \t\t Timestep : 59200 \t\t Average Reward : 400.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "model saved\n",
            "Elapsed Time  :  0:01:19\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode : 434 \t\t Timestep : 60800 \t\t Average Reward : 400.0\n",
            "Episode : 439 \t\t Timestep : 62400 \t\t Average Reward : 311.8\n",
            "Episode : 443 \t\t Timestep : 64000 \t\t Average Reward : 352.25\n",
            "Episode : 448 \t\t Timestep : 65600 \t\t Average Reward : 314.8\n",
            "Episode : 452 \t\t Timestep : 67200 \t\t Average Reward : 400.0\n",
            "Episode : 457 \t\t Timestep : 68800 \t\t Average Reward : 357.6\n",
            "Episode : 461 \t\t Timestep : 70400 \t\t Average Reward : 400.0\n",
            "Episode : 465 \t\t Timestep : 72000 \t\t Average Reward : 400.0\n",
            "Episode : 469 \t\t Timestep : 73600 \t\t Average Reward : 400.0\n",
            "Episode : 473 \t\t Timestep : 75200 \t\t Average Reward : 398.75\n",
            "Episode : 477 \t\t Timestep : 76800 \t\t Average Reward : 400.0\n",
            "Episode : 481 \t\t Timestep : 78400 \t\t Average Reward : 366.0\n",
            "Episode : 485 \t\t Timestep : 80000 \t\t Average Reward : 394.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "model saved\n",
            "Elapsed Time  :  0:01:40\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode : 489 \t\t Timestep : 81600 \t\t Average Reward : 393.75\n",
            "Episode : 493 \t\t Timestep : 83200 \t\t Average Reward : 400.0\n",
            "Episode : 497 \t\t Timestep : 84800 \t\t Average Reward : 395.0\n",
            "Episode : 502 \t\t Timestep : 86400 \t\t Average Reward : 362.4\n",
            "Episode : 506 \t\t Timestep : 88000 \t\t Average Reward : 360.5\n",
            "Episode : 510 \t\t Timestep : 89600 \t\t Average Reward : 400.0\n",
            "Episode : 514 \t\t Timestep : 91200 \t\t Average Reward : 399.75\n",
            "Episode : 518 \t\t Timestep : 92800 \t\t Average Reward : 400.0\n",
            "Episode : 522 \t\t Timestep : 94400 \t\t Average Reward : 400.0\n",
            "Episode : 526 \t\t Timestep : 96000 \t\t Average Reward : 400.0\n",
            "Episode : 531 \t\t Timestep : 97600 \t\t Average Reward : 361.2\n",
            "Episode : 536 \t\t Timestep : 99200 \t\t Average Reward : 315.0\n",
            "--------------------------------------------------------------------------------------------\n",
            "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "model saved\n",
            "Elapsed Time  :  0:02:02\n",
            "--------------------------------------------------------------------------------------------\n",
            "============================================================================================\n",
            "Started training at (GMT) :  2024-08-21 14:37:08\n",
            "Finished training at (GMT) :  2024-08-21 14:39:10\n",
            "Total training time  :  0:02:02\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "env_name = \"CartPole-v1\"\n",
        "has_continuous_action_space = False\n",
        "\n",
        "max_ep_len = 400                    # max timesteps in one episode\n",
        "max_training_timesteps = int(1e5)   # break training loop if timeteps > max_training_timesteps\n",
        "\n",
        "print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
        "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
        "save_model_freq = int(2e4)      # save model frequency (in num timesteps)\n",
        "\n",
        "action_std = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
        "K_epochs = 40               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "\n",
        "lr_actor = 0.0003       # learning rate for actor network\n",
        "lr_critic = 0.001       # learning rate for critic network\n",
        "\n",
        "random_seed = 0         # set random seed if required (0 = no random seed)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"training environment name : \" + env_name)\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "# state space dimension\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# action space dimension\n",
        "if has_continuous_action_space:\n",
        "    action_dim = env.action_space.shape[0]\n",
        "else:\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "log_dir = \"PPO_logs\"\n",
        "if not os.path.exists(log_dir):\n",
        "      os.makedirs(log_dir)\n",
        "\n",
        "log_dir = log_dir + '/' + env_name + '/'\n",
        "if not os.path.exists(log_dir):\n",
        "      os.makedirs(log_dir)\n",
        "\n",
        "\n",
        "run_num = 0\n",
        "current_num_files = next(os.walk(log_dir))[2]\n",
        "run_num = len(current_num_files)\n",
        "\n",
        "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
        "\n",
        "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
        "print(\"logging at : \" + log_f_name)\n",
        "\n",
        "\n",
        "run_num_pretrained = 0\n",
        "\n",
        "directory = \"PPO_preTrained\"\n",
        "if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "\n",
        "directory = directory + '/' + env_name + '/'\n",
        "if not os.path.exists(directory):\n",
        "      os.makedirs(directory)\n",
        "\n",
        "\n",
        "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
        "print(\"save checkpoint path : \" + checkpoint_path)\n",
        "\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"max training timesteps : \", max_training_timesteps)\n",
        "print(\"max timesteps per episode : \", max_ep_len)\n",
        "\n",
        "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
        "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
        "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"state space dimension : \", state_dim)\n",
        "print(\"action space dimension : \", action_dim)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "if has_continuous_action_space:\n",
        "    print(\"Initializing a continuous action space policy\")\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "    print(\"starting std of action distribution : \", action_std)\n",
        "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
        "    print(\"minimum std of action distribution : \", min_action_std)\n",
        "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
        "\n",
        "else:\n",
        "    print(\"Initializing a discrete action space policy\")\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\")\n",
        "print(\"PPO K epochs : \", K_epochs)\n",
        "print(\"PPO epsilon clip : \", eps_clip)\n",
        "print(\"discount factor (gamma) : \", gamma)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "print(\"optimizer learning rate actor : \", lr_actor)\n",
        "print(\"optimizer learning rate critic : \", lr_critic)\n",
        "\n",
        "if random_seed:\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "    print(\"setting random seed to \", random_seed)\n",
        "    torch.manual_seed(random_seed)\n",
        "    env.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "\n",
        "\n",
        "\n",
        "# initialize a PPO agent\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
        "\n",
        "\n",
        "# track total training time\n",
        "start_time = datetime.now().replace(microsecond=0)\n",
        "print(\"Started training at (GMT) : \", start_time)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "# logging file\n",
        "log_f = open(log_f_name,\"w+\")\n",
        "log_f.write('episode,timestep,reward\\n')\n",
        "\n",
        "\n",
        "# printing and logging variables\n",
        "print_running_reward = 0\n",
        "print_running_episodes = 0\n",
        "\n",
        "log_running_reward = 0\n",
        "log_running_episodes = 0\n",
        "\n",
        "time_step = 0\n",
        "i_episode = 0\n",
        "\n",
        "\n",
        "# training loop\n",
        "while time_step <= max_training_timesteps:\n",
        "\n",
        "    state = env.reset()\n",
        "    current_ep_reward = 0\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "\n",
        "        # select action with policy\n",
        "        action = ppo_agent.select_action(state)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "\n",
        "        # saving reward and is_terminals\n",
        "        ppo_agent.buffer.rewards.append(reward)\n",
        "        ppo_agent.buffer.is_terminals.append(done)\n",
        "\n",
        "        time_step +=1\n",
        "        current_ep_reward += reward\n",
        "\n",
        "        # update PPO agent\n",
        "        if time_step % update_timestep == 0:\n",
        "            ppo_agent.update()\n",
        "\n",
        "        # if continuous action space; then decay action std of ouput action distribution\n",
        "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
        "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
        "\n",
        "        # log in logging file\n",
        "        if time_step % log_freq == 0:\n",
        "\n",
        "            # log average reward till last episode\n",
        "            log_avg_reward = log_running_reward / log_running_episodes\n",
        "            log_avg_reward = round(log_avg_reward, 4)\n",
        "\n",
        "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
        "            log_f.flush()\n",
        "\n",
        "            log_running_reward = 0\n",
        "            log_running_episodes = 0\n",
        "\n",
        "        # printing average reward\n",
        "        if time_step % print_freq == 0:\n",
        "\n",
        "            # print average reward till last episode\n",
        "            print_avg_reward = print_running_reward / print_running_episodes\n",
        "            print_avg_reward = round(print_avg_reward, 2)\n",
        "\n",
        "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
        "\n",
        "            print_running_reward = 0\n",
        "            print_running_episodes = 0\n",
        "\n",
        "        # save model weights\n",
        "        if time_step % save_model_freq == 0:\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "            print(\"saving model at : \" + checkpoint_path)\n",
        "            ppo_agent.save(checkpoint_path)\n",
        "            print(\"model saved\")\n",
        "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
        "            print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "        # break; if the episode is over\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    print_running_reward += current_ep_reward\n",
        "    print_running_episodes += 1\n",
        "\n",
        "    log_running_reward += current_ep_reward\n",
        "    log_running_episodes += 1\n",
        "\n",
        "    i_episode += 1\n",
        "\n",
        "\n",
        "log_f.close()\n",
        "env.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print total training time\n",
        "print(\"============================================================================================\")\n",
        "end_time = datetime.now().replace(microsecond=0)\n",
        "print(\"Started training at (GMT) : \", start_time)\n",
        "print(\"Finished training at (GMT) : \", end_time)\n",
        "print(\"Total training time  : \", end_time - start_time)\n",
        "print(\"============================================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRXYImRxcG-X"
      },
      "source": [
        "**Part - III**\n",
        "\n",
        "\n",
        "\n",
        "*  load and test preTrained networks on environments.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P95StGMwmhxY",
        "outputId": "ce78208e-c224-4f54-ed85-dba3e88856d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading network from : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode: 1 \t\t Reward: 400.0\n",
            "Episode: 2 \t\t Reward: 400.0\n",
            "Episode: 3 \t\t Reward: 400.0\n",
            "Episode: 4 \t\t Reward: 400.0\n",
            "Episode: 5 \t\t Reward: 400.0\n",
            "Episode: 6 \t\t Reward: 400.0\n",
            "Episode: 7 \t\t Reward: 400.0\n",
            "Episode: 8 \t\t Reward: 400.0\n",
            "Episode: 9 \t\t Reward: 400.0\n",
            "Episode: 10 \t\t Reward: 400.0\n",
            "============================================================================================\n",
            "average test reward : 400.0\n",
            "============================================================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "env_name = \"CartPole-v1\"\n",
        "has_continuous_action_space = False\n",
        "max_ep_len = 400\n",
        "action_std = None\n",
        "\n",
        "total_test_episodes = 10    # total num of testing episodes\n",
        "\n",
        "K_epochs = 80               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "\n",
        "lr_actor = 0.0003           # learning rate for actor\n",
        "lr_critic = 0.001           # learning rate for critic\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "# state space dimension\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# action space dimension\n",
        "if has_continuous_action_space:\n",
        "    action_dim = env.action_space.shape[0]\n",
        "else:\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "\n",
        "# initialize a PPO agent\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
        "\n",
        "\n",
        "# preTrained weights directory\n",
        "\n",
        "random_seed = 0             #### set this to load a particular checkpoint trained on random seed\n",
        "run_num_pretrained = 0      #### set this to load a particular checkpoint num\n",
        "\n",
        "\n",
        "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
        "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
        "print(\"loading network from : \" + checkpoint_path)\n",
        "\n",
        "ppo_agent.load(checkpoint_path)\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "test_running_reward = 0\n",
        "\n",
        "for ep in range(1, total_test_episodes+1):\n",
        "    ep_reward = 0\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "        action = ppo_agent.select_action(state)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        ep_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "\n",
        "    test_running_reward +=  ep_reward\n",
        "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
        "    ep_reward = 0\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "avg_test_reward = test_running_reward / total_test_episodes\n",
        "avg_test_reward = round(avg_test_reward, 2)\n",
        "print(\"average test reward : \" + str(avg_test_reward))\n",
        "\n",
        "print(\"============================================================================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrdcUS3gZLEm"
      },
      "source": [
        "**Part - IV**\n",
        "\n",
        "\n",
        "*   load log files using pandas\n",
        "*  plot graph using matplotlib\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "hRzgPS5-m90_",
        "outputId": "574b1de7-008a-40fe-887f-43d83b3d324d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data from : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_0.csv\n",
            "data shape :  (125, 3)\n",
            "--------------------------------------------------------------------------------------------\n",
            "loading data from : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_1.csv\n",
            "data shape :  (125, 3)\n",
            "--------------------------------------------------------------------------------------------\n",
            "============================================================================================\n",
            "figure saved at :  PPO_figs/CartPole-v1//PPO_CartPole-v1_fig_0.png\n",
            "============================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "env_name = 'CartPole-v1'\n",
        "\n",
        "fig_num = 0     #### change this to prevent overwriting figures in same env_name folder\n",
        "\n",
        "plot_avg = True    # plot average of all runs; else plot all runs separately\n",
        "\n",
        "fig_width = 10\n",
        "fig_height = 6\n",
        "\n",
        "\n",
        "# smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
        "window_len_smooth = 50\n",
        "min_window_len_smooth = 1\n",
        "linewidth_smooth = 1.5\n",
        "alpha_smooth = 1\n",
        "\n",
        "window_len_var = 5\n",
        "min_window_len_var = 1\n",
        "linewidth_var = 2\n",
        "alpha_var = 0.1\n",
        "\n",
        "\n",
        "colors = ['red', 'blue', 'green', 'orange', 'purple', 'olive', 'brown', 'magenta', 'cyan', 'crimson','gray', 'black']\n",
        "\n",
        "\n",
        "# make directory for saving figures\n",
        "figures_dir = \"PPO_figs\"\n",
        "if not os.path.exists(figures_dir):\n",
        "    os.makedirs(figures_dir)\n",
        "\n",
        "# make environment directory for saving figures\n",
        "figures_dir = figures_dir + '/' + env_name + '/'\n",
        "if not os.path.exists(figures_dir):\n",
        "    os.makedirs(figures_dir)\n",
        "\n",
        "\n",
        "fig_save_path = figures_dir + '/PPO_' + env_name + '_fig_' + str(fig_num) + '.png'\n",
        "\n",
        "\n",
        "# get number of log files in directory\n",
        "log_dir = \"PPO_logs\" + '/' + env_name + '/'\n",
        "\n",
        "current_num_files = next(os.walk(log_dir))[2]\n",
        "num_runs = len(current_num_files)\n",
        "\n",
        "\n",
        "all_runs = []\n",
        "\n",
        "for run_num in range(num_runs):\n",
        "\n",
        "    log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
        "    print(\"loading data from : \" + log_f_name)\n",
        "    data = pd.read_csv(log_f_name)\n",
        "    data = pd.DataFrame(data)\n",
        "\n",
        "    print(\"data shape : \", data.shape)\n",
        "\n",
        "    all_runs.append(data)\n",
        "    print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "ax = plt.gca()\n",
        "\n",
        "if plot_avg:\n",
        "    # average all runs\n",
        "    df_concat = pd.concat(all_runs)\n",
        "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
        "    data_avg = df_concat_groupby.mean()\n",
        "\n",
        "    # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
        "    data_avg['reward_smooth'] = data_avg['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
        "    data_avg['reward_var'] = data_avg['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
        "\n",
        "    data_avg.plot(kind='line', x='timestep' , y='reward_smooth',ax=ax,color=colors[0],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
        "    data_avg.plot(kind='line', x='timestep' , y='reward_var',ax=ax,color=colors[0],  linewidth=linewidth_var, alpha=alpha_var)\n",
        "\n",
        "    # keep only reward_smooth in the legend and rename it\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    ax.legend([handles[0]], [\"reward_avg_\" + str(len(all_runs)) + \"_runs\"], loc=2)\n",
        "\n",
        "\n",
        "else:\n",
        "    for i, run in enumerate(all_runs):\n",
        "        # smooth out rewards to get a smooth and a less smooth (var) plot lines\n",
        "        run['reward_smooth_' + str(i)] = run['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
        "        run['reward_var_' + str(i)] = run['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
        "\n",
        "        # plot the lines\n",
        "        run.plot(kind='line', x='timestep' , y='reward_smooth_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
        "        run.plot(kind='line', x='timestep' , y='reward_var_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_var, alpha=alpha_var)\n",
        "\n",
        "    # keep alternate elements (reward_smooth_i) in the legend\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    new_handles = []\n",
        "    new_labels = []\n",
        "    for i in range(len(handles)):\n",
        "        if(i%2 == 0):\n",
        "            new_handles.append(handles[i])\n",
        "            new_labels.append(labels[i])\n",
        "    ax.legend(new_handles, new_labels, loc=2)\n",
        "\n",
        "\n",
        "\n",
        "# ax.set_yticks(np.arange(0, 1800, 200))\n",
        "# ax.set_xticks(np.arange(0, int(4e6), int(5e5)))\n",
        "\n",
        "\n",
        "ax.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
        "\n",
        "ax.set_xlabel(\"Timesteps\", fontsize=12)\n",
        "ax.set_ylabel(\"Rewards\", fontsize=12)\n",
        "\n",
        "plt.title(env_name, fontsize=14)\n",
        "\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(fig_width, fig_height)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "plt.savefig(fig_save_path)\n",
        "print(\"figure saved at : \", fig_save_path)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtlJ3JS4oW9B",
        "outputId": "9acb2c79-71c6-44e1-a39c-ecdd4641f610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/129 kB 11%] [Waiting\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Ign:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 257 kB in 2s (132 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
            "libassimp-dev is already the newest version (5.2.2~ds0-1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libqt5opengl5-dev is already the newest version (5.15.3+dfsg-2ubuntu0.2).\n",
            "qtbase5-dev is already the newest version (5.15.3+dfsg-2ubuntu0.2).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'sudo apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y cmake ffmpeg pkg-config qtbase5-dev libqt5opengl5-dev libassimp-dev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MoZ1TWt-pLJ6",
        "outputId": "9a02b82a-4339-4ac8-ea8f-4d9d6b1051e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: gym 0.15.4\n",
            "Uninstalling gym-0.15.4:\n",
            "  Successfully uninstalled gym-0.15.4\n",
            "Collecting gym==0.10.9\n",
            "  Using cached gym-0.10.9-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.10.9) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.10.9) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.10.9) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gym==0.10.9) (1.16.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.10.9) (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet>=1.2.0->gym==0.10.9) (1.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.9) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.9) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.9) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.9) (2024.7.4)\n",
            "Installing collected packages: gym\n",
            "Successfully installed gym-0.10.9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gym"
                ]
              },
              "id": "630c40a39b754741bc03d56244614052"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboschool\n",
            "  Using cached roboschool-1.0.34.tar.gz (83.2 MB)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 598, in _prepare_linked_requirement\n",
            "    local_file = unpack_url(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/prepare.py\", line 180, in unpack_url\n",
            "    unpack_file(file.path, location, file.content_type)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/unpacking.py\", line 326, in unpack_file\n",
            "    untar_file(filename, location)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/unpacking.py\", line 181, in untar_file\n",
            "    leading = has_leading_dir([member.name for member in tar.getmembers()])\n",
            "  File \"/usr/lib/python3.10/tarfile.py\", line 1987, in getmembers\n",
            "    self._load()        # all members, we first have to\n",
            "  File \"/usr/lib/python3.10/tarfile.py\", line 2682, in _load\n",
            "    tarinfo = self.next()\n",
            "  File \"/usr/lib/python3.10/tarfile.py\", line 2587, in next\n",
            "    self.fileobj.seek(self.offset - 1)\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 393, in seek\n",
            "    return self._buffer.seek(offset, whence)\n",
            "  File \"/usr/lib/python3.10/_compression.py\", line 153, in seek\n",
            "    data = self.read(min(io.DEFAULT_BUFFER_SIZE, offset))\n",
            "  File \"/usr/lib/python3.10/gzip.py\", line 496, in read\n",
            "    uncompress = self._decompressor.decompress(buf, size)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/os.py\", line 677, in __getitem__\n",
            "    value = self._data[self.encodekey(key)]\n",
            "KeyError: b'FORCE_COLOR'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1685, in print\n",
            "    render_options = self.options.update(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 984, in options\n",
            "    size=self.size,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1003, in size\n",
            "    if self.is_dumb_terminal:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 977, in is_dumb_terminal\n",
            "    return self.is_terminal and is_dumb\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 953, in is_terminal\n",
            "    force_color = self._environ.get(\"FORCE_COLOR\")\n",
            "  File \"/usr/lib/python3.10/_collections_abc.py\", line 824, in get\n",
            "    return self[key]\n",
            "  File \"/usr/lib/python3.10/os.py\", line 680, in __getitem__\n",
            "    raise KeyError(key) from None\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall gym -y\n",
        "!pip install gym==0.10.9\n",
        "!pip install roboschool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzy4-vp55bM7",
        "outputId": "d26116ec-93f5-491e-8175-09300bc0f884"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym==0.15.4 in /usr/local/lib/python3.10/dist-packages (0.15.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.15.4) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.15.4) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gym==0.15.4) (1.16.0)\n",
            "Requirement already satisfied: pyglet<=1.3.2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.15.4) (1.3.2)\n",
            "Requirement already satisfied: cloudpickle~=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.15.4) (1.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from gym==0.15.4) (4.10.0.84)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.4) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install gym==0.15.4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n"
      ],
      "metadata": {
        "id": "3ZbcoL_UU2Cx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poqDHjUiW384",
        "outputId": "413f39de-0110-4907-c7ed-8288a20cc94c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.11).\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  libbz2-dev libpkgconf3 libreadline-dev\n",
            "Use 'apt autoremove' to remove them.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import gym\n",
        "import pybullet_envs\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "# Placeholder for the PPO class - replace this with your actual PPO implementation\n",
        "class PPO:\n",
        "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std=None):\n",
        "        # Initialize your PPO agent here\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.lr_actor = lr_actor\n",
        "        self.lr_critic = lr_critic\n",
        "        self.gamma = gamma\n",
        "        self.K_epochs = K_epochs\n",
        "        self.eps_clip = eps_clip\n",
        "        self.has_continuous_action_space = has_continuous_action_space\n",
        "        self.action_std = action_std\n",
        "        self.buffer = self.Buffer()  # Initialize buffer attribute\n",
        "\n",
        "    def load(self, checkpoint_path):\n",
        "        # Load your pre-trained model weights here\n",
        "        pass\n",
        "\n",
        "    def select_action(self, state):\n",
        "        # Select an action based on the current state\n",
        "        return env.action_space.sample()  # Dummy implementation, replace with actual action selection\n",
        "\n",
        "    class Buffer:\n",
        "        def clear(self):\n",
        "            # Implement buffer clearing logic\n",
        "            pass\n",
        "\n",
        "# Create a virtual display for rendering\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "################## hyperparameters ##################\n",
        "\n",
        "env_name = \"CartPole-v1\"\n",
        "has_continuous_action_space = False\n",
        "max_ep_len = 400\n",
        "action_std = None\n",
        "\n",
        "# env_name = \"LunarLander-v2\"\n",
        "# has_continuous_action_space = False\n",
        "# max_ep_len = 300\n",
        "# action_std = None\n",
        "\n",
        "# env_name = \"BipedalWalker-v2\"\n",
        "# has_continuous_action_space = True\n",
        "# max_ep_len = 1500           # max timesteps in one episode\n",
        "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
        "\n",
        "# env_name = \"MinitaurBulletEnv-v0\"\n",
        "# has_continuous_action_space = True\n",
        "# max_ep_len = 1000           # max timesteps in one episode\n",
        "# action_std = 0.1            # set same std for action distribution which was used while saving\n",
        "\n",
        "total_test_episodes = 1     # save gif for only one episode\n",
        "render_ipython = False      # plot the images using matplotlib and ipythondisplay before saving (slow)\n",
        "K_epochs = 80               # update policy for K epochs\n",
        "eps_clip = 0.2              # clip parameter for PPO\n",
        "gamma = 0.99                # discount factor\n",
        "lr_actor = 0.0003           # learning rate for actor\n",
        "lr_critic = 0.001           # learning rate for critic\n",
        "\n",
        "#####################################################\n",
        "\n",
        "env = gym.make(env_name)\n",
        "\n",
        "# state space dimension\n",
        "state_dim = env.observation_space.shape[0]\n",
        "\n",
        "# action space dimension\n",
        "if has_continuous_action_space:\n",
        "    action_dim = env.action_space.shape[0]\n",
        "else:\n",
        "    action_dim = env.action_space.n\n",
        "\n",
        "# make directory for saving gif images\n",
        "gif_images_dir = \"PPO_gif_images\" + '/'\n",
        "if not os.path.exists(gif_images_dir):\n",
        "    os.makedirs(gif_images_dir)\n",
        "\n",
        "# make environment directory for saving gif images\n",
        "gif_images_dir = gif_images_dir + '/' + env_name + '/'\n",
        "if not os.path.exists(gif_images_dir):\n",
        "    os.makedirs(gif_images_dir)\n",
        "\n",
        "# make directory for gif\n",
        "gif_dir = \"PPO_gifs\" + '/'\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "# make environment directory for gif\n",
        "gif_dir = gif_dir + '/' + env_name  + '/'\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
        "\n",
        "# preTrained weights directory\n",
        "random_seed = 0             # set this to load a particular checkpoint trained on random seed\n",
        "run_num_pretrained = 0      # set this to load a particular checkpoint num\n",
        "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
        "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
        "print(\"loading network from : \" + checkpoint_path)\n",
        "ppo_agent.load(checkpoint_path)\n",
        "print(\"--------------------------------------------------------------------------------------------\")\n",
        "\n",
        "test_running_reward = 0\n",
        "\n",
        "for ep in range(1, total_test_episodes+1):\n",
        "    ep_reward = 0\n",
        "    state = env.reset()\n",
        "\n",
        "    for t in range(1, max_ep_len+1):\n",
        "        action = ppo_agent.select_action(state)\n",
        "        state, reward, done, _ = env.step(action)\n",
        "        ep_reward += reward\n",
        "\n",
        "        img = env.render(mode='rgb_array')\n",
        "\n",
        "        if render_ipython:\n",
        "            plt.imshow(img)\n",
        "            ipythondisplay.clear_output(wait=True)\n",
        "            ipythondisplay.display(plt.gcf())\n",
        "\n",
        "        img = Image.fromarray(img)\n",
        "        img.save(gif_images_dir + '/' + str(t).zfill(6) + '.jpg')\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # clear buffer\n",
        "    ppo_agent.buffer.clear()\n",
        "\n",
        "    test_running_reward += ep_reward\n",
        "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
        "    ep_reward = 0\n",
        "\n",
        "env.close()\n",
        "\n",
        "if render_ipython:\n",
        "    ipythondisplay.clear_output(wait=True)\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "print(\"total number of frames / timesteps / images saved : \", t)\n",
        "avg_test_reward = test_running_reward / total_test_episodes\n",
        "avg_test_reward = round(avg_test_reward, 2)\n",
        "print(\"average test reward : \" + str(avg_test_reward))\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "# Create GIF\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "env_name = 'CartPole-v1'\n",
        "# env_name = 'LunarLander-v2'\n",
        "# env_name = 'BipedalWalker-v2'\n",
        "# env_name = 'RoboschoolWalker2d-v1'\n",
        "\n",
        "gif_num = 0     #### change this to prevent overwriting gifs in same env_name folder\n",
        "\n",
        "# adjust following parameters to get desired duration, size (bytes) and smoothness of gif\n",
        "total_timesteps = 300\n",
        "step = 10\n",
        "frame_duration = 150\n",
        "\n",
        "# input images\n",
        "gif_images_dir = \"PPO_gif_images/\" + env_name + '/*.jpg'\n",
        "\n",
        "# output gif path\n",
        "gif_dir = \"PPO_gifs\"\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "gif_dir = gif_dir + '/' + env_name\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "gif_path = gif_dir + '/PPO_' + env_name + '_gif_' + str(gif_num) + '.gif'\n",
        "\n",
        "img_paths = sorted(glob.glob(gif_images_dir))\n",
        "img_paths = img_paths[:total_timesteps]\n",
        "img_paths = img_paths[::step]\n",
        "\n",
        "print(\"total frames in gif : \", len(img_paths))\n",
        "print(\"total duration of gif : \" + str(round(len(img_paths) * frame_duration / 1000, 2)) + \" seconds\")\n",
        "\n",
        "# save gif\n",
        "img, *imgs = [Image.open(f) for f in img_paths]\n",
        "img.save(fp=gif_path, format='GIF', append_images=imgs, save_all=True, optimize=True, duration=frame_duration, loop=0)\n",
        "\n",
        "print(\"saved gif at : \", gif_path)\n",
        "\n",
        "print(\"============================================================================================\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jR7d8fDmFBlm",
        "outputId": "d03d2213-bf11-4bab-e6e7-d102f0cee809"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "loading network from : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
            "--------------------------------------------------------------------------------------------\n",
            "Episode: 1 \t\t Reward: 20.0\n",
            "============================================================================================\n",
            "total number of frames / timesteps / images saved :  20\n",
            "average test reward : 20.0\n",
            "============================================================================================\n",
            "============================================================================================\n",
            "total frames in gif :  2\n",
            "total duration of gif : 0.3 seconds\n",
            "saved gif at :  PPO_gifs/CartPole-v1/PPO_CartPole-v1_gif_0.gif\n",
            "============================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "######################## generate gif from saved images ########################\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "env_name = 'CartPole-v1'\n",
        "# env_name = 'LunarLander-v2'\n",
        "# env_name = 'BipedalWalker-v2'\n",
        "# env_name = 'RoboschoolWalker2d-v1'\n",
        "\n",
        "\n",
        "gif_num = 0     #### change this to prevent overwriting gifs in same env_name folder\n",
        "\n",
        "# adjust following parameters to get desired duration, size (bytes) and smoothness of gif\n",
        "total_timesteps = 300\n",
        "step = 10\n",
        "frame_duration = 150\n",
        "\n",
        "\n",
        "# input images\n",
        "gif_images_dir = \"PPO_gif_images/\" + env_name + '/*.jpg'\n",
        "\n",
        "\n",
        "# ouput gif path\n",
        "gif_dir = \"PPO_gifs\"\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "gif_dir = gif_dir + '/' + env_name\n",
        "if not os.path.exists(gif_dir):\n",
        "    os.makedirs(gif_dir)\n",
        "\n",
        "gif_path = gif_dir + '/PPO_' + env_name + '_gif_' + str(gif_num) + '.gif'\n",
        "\n",
        "\n",
        "\n",
        "img_paths = sorted(glob.glob(gif_images_dir))\n",
        "img_paths = img_paths[:total_timesteps]\n",
        "img_paths = img_paths[::step]\n",
        "\n",
        "\n",
        "print(\"total frames in gif : \", len(img_paths))\n",
        "print(\"total duration of gif : \" + str(round(len(img_paths) * frame_duration / 1000, 2)) + \" seconds\")\n",
        "\n",
        "\n",
        "\n",
        "# save gif\n",
        "img, *imgs = [Image.open(f) for f in img_paths]\n",
        "img.save(fp=gif_path, format='GIF', append_images=imgs, save_all=True, optimize=True, duration=frame_duration, loop=0)\n",
        "\n",
        "print(\"saved gif at : \", gif_path)\n",
        "\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Chy-oKaZ_g",
        "outputId": "c5fe81c6-8e21-43f2-8b95-da87272f02f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "total frames in gif :  2\n",
            "total duration of gif : 0.3 seconds\n",
            "saved gif at :  PPO_gifs/CartPole-v1/PPO_CartPole-v1_gif_0.gif\n",
            "============================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "env_name = 'CartPole-v1'\n",
        "# env_name = 'LunarLander-v2'\n",
        "# env_name = 'BipedalWalker-v2'\n",
        "# env_name = 'RoboschoolWalker2d-v1'\n",
        "\n",
        "\n",
        "gif_dir = \"PPO_gifs/\" + env_name + '/*.gif'\n",
        "\n",
        "gif_paths = sorted(glob.glob(gif_dir))\n",
        "\n",
        "for gif_path in gif_paths:\n",
        "    file_size = os.path.getsize(gif_path)\n",
        "    print(gif_path + '\\t\\t' + str(round(file_size / (1024 * 1024), 2)) + \" MB\")\n",
        "\n",
        "\n",
        "print(\"============================================================================================\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0YXy3HIaemr",
        "outputId": "9fec2d86-a8e5-4a4f-9d4a-a60677deb8c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================================================\n",
            "PPO_gifs/CartPole-v1/PPO_CartPole-v1_gif_0.gif\t\t0.01 MB\n",
            "============================================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}